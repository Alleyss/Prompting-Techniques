{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Required Packages Installation:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-generativeai in .\\venv\\lib\\site-packages (0.8.4)\n",
      "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in .\\venv\\lib\\site-packages (from google-generativeai) (0.6.15)\n",
      "Requirement already satisfied: google-api-core in .\\venv\\lib\\site-packages (from google-generativeai) (2.24.2)\n",
      "Requirement already satisfied: google-api-python-client in .\\venv\\lib\\site-packages (from google-generativeai) (2.165.0)\n",
      "Requirement already satisfied: google-auth>=2.15.0 in .\\venv\\lib\\site-packages (from google-generativeai) (2.38.0)\n",
      "Requirement already satisfied: protobuf in .\\venv\\lib\\site-packages (from google-generativeai) (5.29.4)\n",
      "Requirement already satisfied: pydantic in .\\venv\\lib\\site-packages (from google-generativeai) (2.10.6)\n",
      "Requirement already satisfied: tqdm in .\\venv\\lib\\site-packages (from google-generativeai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions in .\\venv\\lib\\site-packages (from google-generativeai) (4.12.2)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in .\\venv\\lib\\site-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in .\\venv\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in .\\venv\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in .\\venv\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (4.9)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in .\\venv\\lib\\site-packages (from google-api-core->google-generativeai) (1.69.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.18.0 in .\\venv\\lib\\site-packages (from google-api-core->google-generativeai) (2.32.3)\n",
      "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in .\\venv\\lib\\site-packages (from google-api-python-client->google-generativeai) (0.22.0)\n",
      "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in .\\venv\\lib\\site-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in .\\venv\\lib\\site-packages (from google-api-python-client->google-generativeai) (4.1.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in .\\venv\\lib\\site-packages (from pydantic->google-generativeai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in .\\venv\\lib\\site-packages (from pydantic->google-generativeai) (2.27.2)\n",
      "Requirement already satisfied: colorama in .\\venv\\lib\\site-packages (from tqdm->google-generativeai) (0.4.6)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in .\\venv\\lib\\site-packages (from google-api-core->google-generativeai) (1.71.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in .\\venv\\lib\\site-packages (from google-api-core->google-generativeai) (1.71.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in .\\venv\\lib\\site-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.2)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in .\\venv\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in .\\venv\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in .\\venv\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in .\\venv\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in .\\venv\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2025.1.31)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install google-generativeai\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Starter Code for Gemini Chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import os\n",
    "\n",
    "# Function to initialize Gemini API\n",
    "def initialize_gemini(api_key):\n",
    "    genai.configure(api_key=api_key)\n",
    "\n",
    "# Function to chat with Gemini\n",
    "def chat_with_gemini(prompt, model=\"gemini-2.0-flash\"):\n",
    "    try:\n",
    "        response = genai.GenerativeModel(model).generate_content(prompt)\n",
    "        return response.text\n",
    "    except Exception as e:\n",
    "        return f\"Error: {e}\"\n",
    "\n",
    "# Example usage\n",
    "api_key = os.getenv(\"GOOGLE_API_KEY\")  # Replace with your Gemini API key\n",
    "initialize_gemini(api_key)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zero Shot Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment: Neutral\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# prompt = \"Q:What is the average of 3,4,5,6 A:\"\n",
    "prompt=\"\"\"Classify the text into neutral, negative or positive. \n",
    "Text: I think the vacation is okay.\n",
    "Sentiment:\"\"\"\n",
    "response = chat_with_gemini(prompt)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Few Shot Prompting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The toddler started to farduddle with excitement when he saw the balloons.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt=\"\"\"A \"whatpu\" is a small, furry animal native to Tanzania. An example of a sentence that uses the word whatpu is:\n",
    "We were traveling in Africa and we saw these very cute whatpus.\n",
    " \n",
    "To do a \"farduddle\" means to jump up and down really fast. An example of a sentence that uses the word farduddle is:\"\"\"\n",
    "print(chat_with_gemini(prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt=\"\"\"This is awesome! // Negative\n",
    "This is bad! // Positive\n",
    "Wow that movie was rad! // Positive\n",
    "What a horrible show! //\"\"\"\n",
    "print(chat_with_gemini(prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Limitations of Few-Shot Prompting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's analyze the pattern and solve the last one.\n",
      "\n",
      "The statement is \"The odd numbers in this group add up to an even number.\"\n",
      "To figure this out we only need to focus on the odd numbers in each list.\n",
      "\n",
      "*   **Even Number Rule:** The sum of an even number of odd numbers is always even. The sum of an odd number of odd numbers is always odd.\n",
      "\n",
      "Given list: 15, 32, 5, 13, 82, 7, 1\n",
      "\n",
      "Odd numbers: 15, 5, 13, 7, 1\n",
      "Number of odd numbers in the list: 5 (odd)\n",
      "\n",
      "Since there are 5 odd numbers (an odd number of odd numbers), their sum will be odd.\n",
      "Therefore, the statement \"The odd numbers in this group add up to an even number\" is **False**.\n",
      "\n",
      "**Answer: False**\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt=\"\"\"The odd numbers in this group add up to an even number: 4, 8, 9, 15, 12, 2, 1.\n",
    "A: The answer is False.\n",
    "\n",
    "The odd numbers in this group add up to an even number: 17,  10, 19, 4, 8, 12, 24.\n",
    "A: The answer is True.\n",
    "\n",
    "The odd numbers in this group add up to an even number: 16,  11, 14, 4, 8, 13, 24.\n",
    "A: The answer is True.\n",
    "\n",
    "The odd numbers in this group add up to an even number: 17,  9, 10, 12, 13, 4, 2.\n",
    "A: The answer is False.\n",
    "\n",
    "The odd numbers in this group add up to an even number: 15, 32, 5, 13, 82, 7, 1. \n",
    "A: \"\"\"\n",
    "print(chat_with_gemini(prompt))\n",
    "#Expected Response:\n",
    "# The answer is True.\n",
    "# # Actual Response:\n",
    "# The answer is False.\n",
    "#Note: Nowadays, auto chain of thought is implemented in LLM models,so you wont get the expected response while execution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chain of Thought Zero Shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's how we can break down the problem:\n",
      "\n",
      "1. **Start:** You begin with 10 apples.\n",
      "2. **Giving away:** You give away 2 + 2 = 4 apples.\n",
      "3. **Remaining:** You have 10 - 4 = 6 apples.\n",
      "4. **Buying more:** You buy 5 more apples, so you have 6 + 5 = 11 apples.\n",
      "5. **Eating:** You eat 1 apple, so you have 11 - 1 = 10 apples.\n",
      "\n",
      "**Answer:** You remain with 10 apples.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt=\"\"\"I went to the market and bought 10 apples. I gave 2 apples to the neighbor and 2 to the repairman. I then went and bought 5 more apples and ate 1. How many apples did I remain with?\n",
    "\n",
    "Let's think step by step.\"\"\"\n",
    "print(chat_with_gemini(prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chain of Thought Few Shot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding all the odd numbers (15, 5, 13, 7, 1) gives 41. The answer is False.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt=\"\"\"The odd numbers in this group add up to an even number: 4, 8, 9, 15, 12, 2, 1.\n",
    "A: Adding all the odd numbers (9, 15, 1) gives 25. The answer is False.\n",
    "The odd numbers in this group add up to an even number: 17,  10, 19, 4, 8, 12, 24.\n",
    "A: Adding all the odd numbers (17, 19) gives 36. The answer is True.\n",
    "The odd numbers in this group add up to an even number: 16,  11, 14, 4, 8, 13, 24.\n",
    "A: Adding all the odd numbers (11, 13) gives 24. The answer is True.\n",
    "The odd numbers in this group add up to an even number: 17,  9, 10, 12, 13, 4, 2.\n",
    "A: Adding all the odd numbers (17, 9, 13) gives 39. The answer is False.\n",
    "The odd numbers in this group add up to an even number: 15, 32, 5, 13, 82, 7, 1. \n",
    "A:\"\"\"\n",
    "print(chat_with_gemini(prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Meta Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Okay, let's break down the importance of AI in healthcare, step by step.\n",
      "\n",
      "**Introduction:**\n",
      "\n",
      "Artificial intelligence (AI) is rapidly transforming the healthcare industry, offering innovative solutions to improve patient outcomes, streamline processes, and reduce costs. Its ability to analyze vast amounts of data, identify patterns, and automate tasks makes it a powerful tool for enhancing various aspects of healthcare delivery.\n",
      "\n",
      "**Key Benefits of AI in Healthcare:**\n",
      "\n",
      "AI's impact on healthcare is significant and multifaceted. Here are some key benefits:\n",
      "\n",
      "*   **Improved Diagnostics:** AI algorithms can analyze medical images (X-rays, MRIs, CT scans) to detect anomalies and diseases earlier and more accurately than human radiologists. This can lead to faster diagnoses and more effective treatment.\n",
      "*   **Personalized Treatment Plans:** AI can analyze a patient's medical history, genetic information, lifestyle, and other relevant data to develop personalized treatment plans that are tailored to their specific needs. This can improve treatment effectiveness and reduce side effects.\n",
      "*   **Drug Discovery and Development:** AI can accelerate the drug discovery and development process by identifying potential drug candidates, predicting their efficacy, and optimizing clinical trial designs. This can lead to faster and more efficient development of new treatments.\n",
      "*   **Robotic Surgery:** AI-powered surgical robots can perform complex procedures with greater precision and control than human surgeons, leading to smaller incisions, reduced blood loss, and faster recovery times.\n",
      "*   **Predictive Analytics:** AI can analyze patient data to identify individuals who are at high risk of developing certain diseases or experiencing adverse events. This allows healthcare providers to intervene early and prevent these problems from occurring.\n",
      "*   **Streamlined Administrative Tasks:** AI can automate administrative tasks such as appointment scheduling, billing, and insurance claims processing, freeing up healthcare professionals to focus on patient care.\n",
      "*   **Enhanced Patient Monitoring:** Wearable sensors and AI algorithms can continuously monitor patients' vital signs and activity levels, providing real-time alerts to healthcare providers if any abnormalities are detected. This allows for timely intervention and can prevent serious health complications.\n",
      "\n",
      "**Real-World Examples and Case Studies:**\n",
      "\n",
      "*   **Google's DeepMind and Diabetic Retinopathy:** Google's DeepMind developed an AI system that can diagnose diabetic retinopathy (a leading cause of blindness) with an accuracy rate comparable to that of expert ophthalmologists. This technology is being used in clinics around the world to screen patients for this condition and prevent vision loss.\n",
      "*   **IBM Watson Oncology:** IBM Watson Oncology is an AI platform that provides evidence-based treatment recommendations for cancer patients. It analyzes patient data, including medical history, genetic information, and clinical trial results, to help oncologists develop personalized treatment plans. Several hospitals and cancer centers have adopted Watson Oncology to improve cancer care.\n",
      "*   **PathAI and Cancer Diagnosis:** PathAI utilizes AI to assist pathologists in diagnosing cancer from tissue samples. By identifying subtle patterns and anomalies that may be missed by the human eye, PathAI's technology improves diagnostic accuracy and efficiency, leading to better patient outcomes.\n",
      "*   **Butterfly Network and Ultrasound:** Butterfly Network has developed a handheld ultrasound device that is powered by AI. This device makes ultrasound imaging more accessible and affordable, allowing healthcare providers to perform rapid and accurate diagnoses at the point of care. It has been used in remote areas and during emergencies.\n",
      "\n",
      "**Challenges and Ethical Concerns:**\n",
      "\n",
      "Despite the significant potential of AI in healthcare, there are also several challenges and ethical concerns that need to be addressed:\n",
      "\n",
      "*   **Data Privacy and Security:** AI algorithms require access to large amounts of patient data, which raises concerns about data privacy and security. It is crucial to implement robust security measures to protect patient data from unauthorized access and misuse.\n",
      "*   **Bias and Fairness:** AI algorithms can be biased if they are trained on biased data. This can lead to discriminatory outcomes for certain patient populations. It is important to carefully evaluate AI algorithms for bias and ensure that they are fair and equitable.\n",
      "*   **Transparency and Explainability:** Some AI algorithms are \"black boxes,\" meaning that it is difficult to understand how they arrive at their conclusions. This lack of transparency can make it difficult for healthcare professionals to trust and use these algorithms. It is important to develop AI algorithms that are transparent and explainable.\n",
      "*   **Job Displacement:** The increasing use of AI in healthcare could lead to job displacement for some healthcare professionals. It is important to provide training and support to help these professionals adapt to the changing landscape of healthcare.\n",
      "*   **Over-reliance on AI:** There's a risk of over-reliance on AI systems, potentially diminishing the importance of human judgment and empathy in healthcare. Maintaining a balance between AI assistance and human interaction is crucial.\n",
      "\n",
      "**Conclusion:**\n",
      "\n",
      "AI holds immense promise for revolutionizing healthcare by improving diagnostics, personalizing treatments, accelerating drug discovery, and streamlining administrative tasks. While challenges related to data privacy, bias, transparency, and job displacement must be addressed, the potential benefits of AI in healthcare are undeniable. As AI technology continues to evolve, it will play an increasingly important role in shaping the future of healthcare, leading to better patient outcomes, reduced costs, and a more efficient healthcare system. Embracing AI responsibly and ethically will be key to unlocking its full potential and ensuring that it benefits all patients.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt=\"\"\"You are an AI assistant designed to provide detailed, structured, and well-reasoned responses. Your goal is to think step by step and ensure clarity in your explanation.  \n",
    "\n",
    "**Task:** Explain the importance of AI in healthcare with an example.  \n",
    "\n",
    "**Instructions:**  \n",
    "1. Begin by introducing the topic concisely.  \n",
    "2. List the key benefits of AI in healthcare (use bullet points).  \n",
    "3. Provide real-world examples or case studies.  \n",
    "4. Address any potential challenges or ethical concerns.  \n",
    "5. Conclude with a balanced summary.  \n",
    "\n",
    "Follow this structure carefully and ensure your response is informative and engaging.\n",
    "\n",
    "\"\"\"\n",
    "print(chat_with_gemini(prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Self Consistency: multiple few cot response generation to get consistent answer everytime."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generated Knowledge Prompting: generate knowledge using few shot then using the knowledge to generate response.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "knowledge:The goal in golf is to play the fewest strokes to complete a round. A round usually consists of 18 holes. The golfer with the lowest score wins.\n",
      "\n",
      "Response:The goal in golf is to get the **lowest** score, not the highest. Therefore, the statement is incorrect.\n",
      "\n",
      "**Answer: No**\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt=\"\"\"Input: Greece is larger than mexico.\n",
    "Knowledge: Greece is approximately 131,957 sq km, while Mexico is approximately 1,964,375 sq km, making Mexico 1,389% larger than Greece.\n",
    "\n",
    "Input: Glasses always fog up.\n",
    "Knowledge: Condensation occurs on eyeglass lenses when water vapor from your sweat, breath, and ambient humidity lands on a cold surface, cools, and then changes into tiny drops of liquid, forming a film that you see as fog. Your lenses will be relatively cool compared to your breath, especially when the outside air is cold.\n",
    "\n",
    "Input: A fish is capable of thinking.\n",
    "Knowledge: Fish are more intelligent than they appear. In many areas, such as memory, their cognitive powers match or exceed those of ’higher’ vertebrates including non-human primates. Fish’s long-term memories help them keep track of complex social relationships.\n",
    "\n",
    "Input: A common effect of smoking lots of cigarettes in one’s lifetime is a higher than normal chance of getting lung cancer.\n",
    "Knowledge: Those who consistently averaged less than one cigarette per day over their lifetime had nine times the risk of dying from lung cancer than never smokers. Among people who smoked between one and 10 cigarettes per day, the risk of dying from lung cancer was nearly 12 times higher than that of never smokers.\n",
    "\n",
    "Input: A rock is the same size as a pebble.\n",
    "Knowledge: A pebble is a clast of rock with a particle size of 4 to 64 millimetres based on the Udden-Wentworth scale of sedimentology. Pebbles are generally considered larger than granules (2 to 4 millimetres diameter) and smaller than cobbles (64 to 256 millimetres diameter).\n",
    "\n",
    "Input: Part of golf is trying to get a higher point total than others.\n",
    "Knowledge:\"\"\"\n",
    "knowledge=chat_with_gemini(prompt)\n",
    "print(\"knowledge:\"+knowledge)\n",
    "updated_prompt=\"\"\"Question: Part of golf is trying to get a higher point total than others. Yes or No?\n",
    "knowledge:\"\"\"+knowledge+\"Explain and Answer\"\n",
    "print(\"Response:\"+chat_with_gemini(updated_prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prompt Chaining: Break Tasks into Sub Tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Introduction Options:\n",
      "\n",
      "**Option 1 (Focus on Transformation):**\n",
      "\n",
      "Imagine a world where diagnoses are faster and more accurate, treatments are tailored to your unique needs, and life-saving drugs are developed in record time. This isn't science fiction; it's the rapidly evolving reality of artificial intelligence in healthcare. From algorithms that detect cancer in medical images with superhuman precision to virtual assistants providing round-the-clock support, AI is poised to revolutionize every facet of medicine. Let's explore the remarkable benefits AI is bringing to healthcare, unlocking a future of improved outcomes, increased efficiency, and unprecedented access to care for all.\n",
      "\n",
      "**Option 2 (Highlighting Current Impact):**\n",
      "\n",
      "Artificial intelligence is no longer a futuristic concept confined to research labs; it's actively reshaping the landscape of modern healthcare. Already, AI algorithms are assisting doctors in identifying diseases earlier, personalizing treatment plans for maximum effectiveness, and even accelerating the development of life-saving drugs. But the impact doesn't stop there. This exploration delves into the many ways AI is transforming healthcare, from improved diagnostic accuracy and enhanced drug discovery to streamlined operations and increased accessibility to care, demonstrating its potential to revolutionize the medical field as we know it.\n",
      "\n",
      "**Option 3 (Emphasizing Patient Benefit):**\n",
      "\n",
      "Tired of diagnostic delays, generic treatments, and the overwhelming cost of healthcare? Artificial intelligence offers a powerful solution, promising a future where healthcare is more personalized, efficient, and accessible than ever before. By analyzing vast amounts of data, AI is empowering doctors to make more informed decisions, enabling personalized treatment plans that target individual needs, and even streamlining administrative tasks to reduce costs. Join us as we uncover the numerous benefits of AI in healthcare, highlighting how it's poised to improve patient outcomes and reshape the future of medicine.\n",
      "\n",
      "## Conclusion Options:\n",
      "\n",
      "**Option 1 (Looking Forward):**\n",
      "\n",
      "From its ability to detect diseases with greater accuracy to its potential to personalize treatment plans and accelerate drug discovery, AI is fundamentally changing healthcare. While careful consideration and ethical guidelines are crucial, the transformative power of AI is undeniable. As research continues and these technologies mature, we can anticipate a future where healthcare is more precise, proactive, and accessible, ultimately leading to healthier lives for all. The journey of AI in healthcare has just begun, and the potential to reshape the medical landscape is truly within reach.\n",
      "\n",
      "**Option 2 (Emphasis on Comprehensive Impact):**\n",
      "\n",
      "The evidence is clear: AI is not just a technological advancement but a powerful catalyst for positive change across the entire healthcare spectrum. From streamlining administrative tasks and reducing costs to improving diagnostic accuracy and accelerating research, AI's benefits are far-reaching. By embracing these innovations responsibly and continuing to explore its vast potential, we can unlock a future where healthcare is more efficient, effective, and equitable for everyone. The future of medicine is here, and it's powered by AI.\n",
      "\n",
      "**Option 3 (Focus on Accessible, Efficient, Accurate Future):**\n",
      "\n",
      "In summary, AI is not just a futuristic concept; it is already having a significant impact on healthcare today. Its ability to improve diagnostics, personalize treatment, accelerate drug discovery, streamline operations, and increase access to care is transforming the medical landscape. While ongoing research and responsible implementation are vital, the potential for AI to revolutionize healthcare is undeniable, promising a future of medicine that is more accurate, efficient, and accessible for all.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "prompt1=\"List the key benefits of AI in healthcare.\"\n",
    "response1=chat_with_gemini(prompt1)\n",
    "\n",
    "prompt2=\"Expand on each benefit with real-world examples.\"\n",
    "response2=chat_with_gemini(prompt2+response1)\n",
    "prompt3=\"Write an engaging introduction and conclusion based on the benefits listed.\" \n",
    "response3=chat_with_gemini(prompt3+response2)\n",
    "print(response3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tree of Thoughts (ToT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Okay, let's begin. We have three experts ready to tackle this problem.\n",
      "\n",
      "**Expert 1 (Algebra Ace):** My first step is to find a common denominator for 'a+b' and 'a-b' separately.  This will make the addition and subtraction easier.  For 'a+b', I'll be looking at (2x+1)/(x-1) + (x+1)/(2x-1).\n",
      "\n",
      "**Expert 2 (Fraction Fanatic):** My first step is to calculate 'a+b'.  Using the common denominator (x-1)(2x-1), I can rewrite the expression.\n",
      "\n",
      "**Expert 3 (Simplification Sage):** My first step is to calculate 'a-b'. Using the common denominator (x-1)(2x-1), I can rewrite the expression.\n",
      "\n",
      "Okay, let's see what they've come up with for step two.\n",
      "\n",
      "**Expert 1 (Algebra Ace):** Still focusing on setting things up, I'll find the common denominator for 'a-b' which is also (x-1)(2x-1) and write the expression (2x+1)/(x-1) - (x+1)/(2x-1).\n",
      "\n",
      "**Expert 2 (Fraction Fanatic):**  Okay, a+b =  [(2x+1)(2x-1) + (x+1)(x-1)] / [(x-1)(2x-1)].  Now I need to expand those products.\n",
      "\n",
      "**Expert 3 (Simplification Sage):** Okay, a-b =  [(2x+1)(2x-1) - (x+1)(x-1)] / [(x-1)(2x-1)].  Now I need to expand those products.\n",
      "\n",
      "Let's move on to step three.\n",
      "\n",
      "**Expert 1 (Algebra Ace):** I'm realizing I might be taking a less efficient route. While finding common denominators for both a+b and a-b separately is correct, it's adding extra steps. I'm going to bow out. Good luck, team!\n",
      "\n",
      "*Expert 1 has left the building.*\n",
      "\n",
      "**Expert 2 (Fraction Fanatic):** Expanding the numerator of a+b, I get: (4x^2 - 1 + x^2 - 1) / [(x-1)(2x-1)] = (5x^2 - 2) / [(x-1)(2x-1)].\n",
      "\n",
      "**Expert 3 (Simplification Sage):** Expanding the numerator of a-b, I get: (4x^2 - 1 - (x^2 - 1)) / [(x-1)(2x-1)] = (3x^2) / [(x-1)(2x-1)].\n",
      "\n",
      "Time for step four.\n",
      "\n",
      "**Expert 2 (Fraction Fanatic):** Now I need to divide (a+b) by (a-b). This means dividing (5x^2 - 2) / [(x-1)(2x-1)] by (3x^2) / [(x-1)(2x-1)].  Which is the same as multiplying by the reciprocal of the second fraction.\n",
      "\n",
      "**Expert 3 (Simplification Sage):** I think I'm on the right track, so I'll wait for expert 2 to proceed, and then provide a check.\n",
      "\n",
      "Let's continue to step five.\n",
      "\n",
      "**Expert 2 (Fraction Fanatic):** Dividing (5x^2 - 2) / [(x-1)(2x-1)] by (3x^2) / [(x-1)(2x-1)] gives us:  [(5x^2 - 2) / (x-1)(2x-1)] * [(x-1)(2x-1) / (3x^2)].  The (x-1)(2x-1) terms cancel! So we have (5x^2 - 2) / (3x^2).\n",
      "\n",
      "**Expert 3 (Simplification Sage):** I agree with Expert 2.  Therefore, the final answer is (5x^2 - 2) / (3x^2).\n",
      "\n",
      "**Final Answer:** The value of (a+b)/(a-b) is (5x^2 - 2) / (3x^2).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt=\"\"\"Imagine three different experts are answering this question.\n",
    "All experts will write down 1 step of their thinking,\n",
    "then share it with the group.\n",
    "Then all experts will go on to the next step, etc.\n",
    "If any expert realises they're wrong at any point then they leave.\n",
    "The question is If a = (2x+1)/(x-1) and b = (x+1)/(2x-1), what is the value of (a+b)/(a-b)?\"\"\"\n",
    "print(chat_with_gemini(prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RAG in rag.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting faiss-cpu\n",
      "  Using cached faiss_cpu-1.10.0-cp311-cp311-win_amd64.whl (13.7 MB)\n",
      "Collecting langchain\n",
      "  Using cached langchain-0.3.21-py3-none-any.whl (1.0 MB)\n",
      "Requirement already satisfied: numpy<3.0,>=1.25.0 in .\\venv\\lib\\site-packages (from faiss-cpu) (2.2.4)\n",
      "Requirement already satisfied: packaging in .\\venv\\lib\\site-packages (from faiss-cpu) (24.2)\n",
      "Collecting langchain-core<1.0.0,>=0.3.45 (from langchain)\n",
      "  Using cached langchain_core-0.3.47-py3-none-any.whl (417 kB)\n",
      "Collecting langchain-text-splitters<1.0.0,>=0.3.7 (from langchain)\n",
      "  Using cached langchain_text_splitters-0.3.7-py3-none-any.whl (32 kB)\n",
      "Collecting langsmith<0.4,>=0.1.17 (from langchain)\n",
      "  Using cached langsmith-0.3.18-py3-none-any.whl (351 kB)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in .\\venv\\lib\\site-packages (from langchain) (2.10.6)\n",
      "Collecting SQLAlchemy<3,>=1.4 (from langchain)\n",
      "  Using cached sqlalchemy-2.0.39-cp311-cp311-win_amd64.whl (2.1 MB)\n",
      "Requirement already satisfied: requests<3,>=2 in .\\venv\\lib\\site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in .\\venv\\lib\\site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in .\\venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.45->langchain) (9.0.0)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<1.0.0,>=0.3.45->langchain)\n",
      "  Using cached jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in .\\venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.45->langchain) (4.12.2)\n",
      "Collecting httpx<1,>=0.23.0 (from langsmith<0.4,>=0.1.17->langchain)\n",
      "  Using cached httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in .\\venv\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.15)\n",
      "Collecting requests-toolbelt<2.0.0,>=1.0.0 (from langsmith<0.4,>=0.1.17->langchain)\n",
      "  Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in .\\venv\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in .\\venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in .\\venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in .\\venv\\lib\\site-packages (from requests<3,>=2->langchain) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in .\\venv\\lib\\site-packages (from requests<3,>=2->langchain) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in .\\venv\\lib\\site-packages (from requests<3,>=2->langchain) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in .\\venv\\lib\\site-packages (from requests<3,>=2->langchain) (2025.1.31)\n",
      "Collecting greenlet!=0.4.17 (from SQLAlchemy<3,>=1.4->langchain)\n",
      "  Using cached greenlet-3.1.1-cp311-cp311-win_amd64.whl (298 kB)\n",
      "Collecting anyio (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain)\n",
      "  Using cached anyio-4.9.0-py3-none-any.whl (100 kB)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain)\n",
      "  Using cached httpcore-1.0.7-py3-none-any.whl (78 kB)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain)\n",
      "  Using cached h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in .\\venv\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.45->langchain) (3.0.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in .\\venv\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.3.1)\n",
      "Installing collected packages: jsonpatch, h11, greenlet, faiss-cpu, anyio, SQLAlchemy, requests-toolbelt, httpcore, httpx, langsmith, langchain-core, langchain-text-splitters, langchain\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not install packages due to an OSError: [WinError 32] The process cannot access the file because it is being used by another process: 'D:\\\\vs-workspace\\\\tericsoft_tasks\\\\prompting\\\\venv\\\\Lib\\\\site-packages\\\\sqlalchemy\\\\orm\\\\strategy_options.py'\n",
      "Check the permissions.\n",
      "\n",
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install faiss-cpu langchain\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Program Aided Language Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```python\n",
      "from datetime import datetime\n",
      "from dateutil.relativedelta import relativedelta\n",
      "\n",
      "# Today is 27 February 2023.\n",
      "today = datetime(2023, 2, 27)\n",
      "# I was born exactly 25 years ago.\n",
      "birthday = today - relativedelta(years=25)\n",
      "# The answer formatted with %m/%d/%Y is\n",
      "birthday.strftime('%m/%d/%Y')\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "prompt=\"\"\"\n",
    "# Q: 2015 is coming in 36 hours. What is the date one week from today in MM/DD/YYYY?\n",
    "# If 2015 is coming in 36 hours, then today is 36 hours before.\n",
    "today = datetime(2015, 1, 1) - relativedelta(hours=36)\n",
    "# One week from today,\n",
    "one_week_from_today = today + relativedelta(weeks=1)\n",
    "# The answer formatted with %m/%d/%Y is\n",
    "one_week_from_today.strftime('%m/%d/%Y')\n",
    "# Q: The first day of 2019 is a Tuesday, and today is the first Monday of 2019. What is the date today in MM/DD/YYYY?\n",
    "# If the first day of 2019 is a Tuesday, and today is the first Monday of 2019, then today is 6 days later.\n",
    "today = datetime(2019, 1, 1) + relativedelta(days=6)\n",
    "# The answer formatted with %m/%d/%Y is\n",
    "today.strftime('%m/%d/%Y')\n",
    "# Q: The concert was scheduled to be on 06/01/1943, but was delayed by one day to today. What is the date 10 days ago in MM/DD/YYYY?\n",
    "# If the concert was scheduled to be on 06/01/1943, but was delayed by one day to today, then today is one day later.\n",
    "today = datetime(1943, 6, 1) + relativedelta(days=1)\n",
    "# 10 days ago,\n",
    "ten_days_ago = today - relativedelta(days=10)\n",
    "# The answer formatted with %m/%d/%Y is\n",
    "ten_days_ago.strftime('%m/%d/%Y')\n",
    "# Q: It is 4/19/1969 today. What is the date 24 hours later in MM/DD/YYYY?\n",
    "# It is 4/19/1969 today.\n",
    "today = datetime(1969, 4, 19)\n",
    "# 24 hours later,\n",
    "later = today + relativedelta(hours=24)\n",
    "# The answer formatted with %m/%d/%Y is\n",
    "today.strftime('%m/%d/%Y')\n",
    "# Q: Jane thought today is 3/11/2002, but today is in fact Mar 12, which is 1 day later. What is the date 24 hours later in MM/DD/YYYY?\n",
    "# If Jane thought today is 3/11/2002, but today is in fact Mar 12, then today is 3/12/2002.\n",
    "today = datetime(2002, 3, 12)\n",
    "# 24 hours later,\n",
    "later = today + relativedelta(hours=24)\n",
    "# The answer formatted with %m/%d/%Y is\n",
    "later.strftime('%m/%d/%Y')\n",
    "# Q: Jane was born on the last day of Feburary in 2001. Today is her 16-year-old birthday. What is the date yesterday in MM/DD/YYYY?\n",
    "# If Jane was born on the last day of Feburary in 2001 and today is her 16-year-old birthday, then today is 16 years later.\n",
    "today = datetime(2001, 2, 28) + relativedelta(years=16)\n",
    "# Yesterday,\n",
    "yesterday = today - relativedelta(days=1)\n",
    "# The answer formatted with %m/%d/%Y is\n",
    "yesterday.strftime('%m/%d/%Y')\n",
    "# Q: {question}\n",
    "\"\"\".strip() + '\\n'\n",
    "question = \"Today is 27 February 2023. I was born exactly 25 years ago. What is the date I was born in MM/DD/YYYY?\"\n",
    "response=chat_with_gemini(prompt.format(question=question))\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting googlesearch-python\n",
      "  Downloading googlesearch_python-1.3.0-py3-none-any.whl (5.6 kB)\n",
      "Collecting beautifulsoup4>=4.9 (from googlesearch-python)\n",
      "  Using cached beautifulsoup4-4.13.3-py3-none-any.whl (186 kB)\n",
      "Requirement already satisfied: requests>=2.20 in .\\venv\\lib\\site-packages (from googlesearch-python) (2.32.3)\n",
      "Collecting soupsieve>1.2 (from beautifulsoup4>=4.9->googlesearch-python)\n",
      "  Using cached soupsieve-2.6-py3-none-any.whl (36 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in .\\venv\\lib\\site-packages (from beautifulsoup4>=4.9->googlesearch-python) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in .\\venv\\lib\\site-packages (from requests>=2.20->googlesearch-python) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in .\\venv\\lib\\site-packages (from requests>=2.20->googlesearch-python) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in .\\venv\\lib\\site-packages (from requests>=2.20->googlesearch-python) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in .\\venv\\lib\\site-packages (from requests>=2.20->googlesearch-python) (2025.1.31)\n",
      "Installing collected packages: soupsieve, beautifulsoup4, googlesearch-python\n",
      "Successfully installed beautifulsoup4-4.13.3 googlesearch-python-1.3.0 soupsieve-2.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install googlesearch-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain-community\n",
      "  Using cached langchain_community-0.3.20-py3-none-any.whl (2.5 MB)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.45 in .\\venv\\lib\\site-packages (from langchain-community) (0.3.47)\n",
      "Requirement already satisfied: langchain<1.0.0,>=0.3.21 in .\\venv\\lib\\site-packages (from langchain-community) (0.3.21)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in .\\venv\\lib\\site-packages (from langchain-community) (2.0.39)\n",
      "Requirement already satisfied: requests<3,>=2 in .\\venv\\lib\\site-packages (from langchain-community) (2.32.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in .\\venv\\lib\\site-packages (from langchain-community) (6.0.2)\n",
      "Collecting aiohttp<4.0.0,>=3.8.3 (from langchain-community)\n",
      "  Using cached aiohttp-3.11.14-cp311-cp311-win_amd64.whl (443 kB)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in .\\venv\\lib\\site-packages (from langchain-community) (9.0.0)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
      "  Using cached dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n",
      "  Using cached pydantic_settings-2.8.1-py3-none-any.whl (30 kB)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.125 in .\\venv\\lib\\site-packages (from langchain-community) (0.3.18)\n",
      "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain-community)\n",
      "  Using cached httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
      "Requirement already satisfied: numpy<3,>=1.26.2 in .\\venv\\lib\\site-packages (from langchain-community) (2.2.4)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Using cached aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Using cached attrs-25.3.0-py3-none-any.whl (63 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Using cached frozenlist-1.5.0-cp311-cp311-win_amd64.whl (51 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Using cached multidict-6.2.0-cp311-cp311-win_amd64.whl (29 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Using cached propcache-0.3.0-cp311-cp311-win_amd64.whl (44 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Using cached yarl-1.18.3-cp311-cp311-win_amd64.whl (91 kB)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Using cached marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Using cached typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.7 in .\\venv\\lib\\site-packages (from langchain<1.0.0,>=0.3.21->langchain-community) (0.3.7)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in .\\venv\\lib\\site-packages (from langchain<1.0.0,>=0.3.21->langchain-community) (2.10.6)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in .\\venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.45->langchain-community) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in .\\venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.45->langchain-community) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in .\\venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.45->langchain-community) (4.12.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in .\\venv\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in .\\venv\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-community) (3.10.15)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in .\\venv\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in .\\venv\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.23.0)\n",
      "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain-community)\n",
      "  Using cached python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in .\\venv\\lib\\site-packages (from requests<3,>=2->langchain-community) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in .\\venv\\lib\\site-packages (from requests<3,>=2->langchain-community) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in .\\venv\\lib\\site-packages (from requests<3,>=2->langchain-community) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in .\\venv\\lib\\site-packages (from requests<3,>=2->langchain-community) (2025.1.31)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in .\\venv\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.1.1)\n",
      "Requirement already satisfied: anyio in .\\venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (4.9.0)\n",
      "Requirement already satisfied: httpcore==1.* in .\\venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in .\\venv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in .\\venv\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.45->langchain-community) (3.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in .\\venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.21->langchain-community) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in .\\venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.21->langchain-community) (2.27.2)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Using cached mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Requirement already satisfied: sniffio>=1.1 in .\\venv\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.3.1)\n",
      "Installing collected packages: python-dotenv, propcache, mypy-extensions, multidict, marshmallow, httpx-sse, frozenlist, attrs, aiohappyeyeballs, yarl, typing-inspect, aiosignal, pydantic-settings, dataclasses-json, aiohttp, langchain-community\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not install packages due to an OSError: [WinError 32] The process cannot access the file because it is being used by another process: 'D:\\\\vs-workspace\\\\tericsoft_tasks\\\\prompting\\\\venv\\\\Lib\\\\site-packages\\\\langchain_community\\\\chat_models\\\\gigachat.py'\n",
      "Check the permissions.\n",
      "\n",
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain-community\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain-google-genai\n",
      "  Downloading langchain_google_genai-2.1.1-py3-none-any.whl (40 kB)\n",
      "                                              0.0/40.8 kB ? eta -:--:--\n",
      "     ---------------------------------------- 40.8/40.8 kB 2.0 MB/s eta 0:00:00\n",
      "Collecting filetype<2.0.0,>=1.2.0 (from langchain-google-genai)\n",
      "  Using cached filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
      "Collecting google-ai-generativelanguage<0.7.0,>=0.6.16 (from langchain-google-genai)\n",
      "  Using cached google_ai_generativelanguage-0.6.17-py3-none-any.whl (1.4 MB)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.47 in .\\venv\\lib\\site-packages (from langchain-google-genai) (0.3.47)\n",
      "Requirement already satisfied: pydantic<3,>=2 in .\\venv\\lib\\site-packages (from langchain-google-genai) (2.10.6)\n",
      "Requirement already satisfied: google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1 in .\\venv\\lib\\site-packages (from google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (2.24.2)\n",
      "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1 in .\\venv\\lib\\site-packages (from google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (2.38.0)\n",
      "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in .\\venv\\lib\\site-packages (from google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (1.26.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in .\\venv\\lib\\site-packages (from google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (5.29.4)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.125 in .\\venv\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.47->langchain-google-genai) (0.3.18)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in .\\venv\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.47->langchain-google-genai) (9.0.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in .\\venv\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.47->langchain-google-genai) (1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in .\\venv\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.47->langchain-google-genai) (6.0.2)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in .\\venv\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.47->langchain-google-genai) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in .\\venv\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.47->langchain-google-genai) (4.12.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in .\\venv\\lib\\site-packages (from pydantic<3,>=2->langchain-google-genai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in .\\venv\\lib\\site-packages (from pydantic<3,>=2->langchain-google-genai) (2.27.2)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in .\\venv\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (1.69.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.18.0 in .\\venv\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (2.32.3)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in .\\venv\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (1.71.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in .\\venv\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (1.71.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in .\\venv\\lib\\site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in .\\venv\\lib\\site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in .\\venv\\lib\\site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (4.9)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in .\\venv\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.47->langchain-google-genai) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in .\\venv\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.47->langchain-google-genai) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in .\\venv\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.47->langchain-google-genai) (3.10.15)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in .\\venv\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.47->langchain-google-genai) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in .\\venv\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.47->langchain-google-genai) (0.23.0)\n",
      "Requirement already satisfied: anyio in .\\venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.47->langchain-google-genai) (4.9.0)\n",
      "Requirement already satisfied: certifi in .\\venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.47->langchain-google-genai) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in .\\venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.47->langchain-google-genai) (1.0.7)\n",
      "Requirement already satisfied: idna in .\\venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.47->langchain-google-genai) (3.10)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in .\\venv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.47->langchain-google-genai) (0.14.0)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in .\\venv\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (0.6.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in .\\venv\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in .\\venv\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (2.3.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in .\\venv\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.47->langchain-google-genai) (1.3.1)\n",
      "Installing collected packages: filetype, google-ai-generativelanguage, langchain-google-genai\n",
      "  Attempting uninstall: google-ai-generativelanguage\n",
      "    Found existing installation: google-ai-generativelanguage 0.6.15\n",
      "    Uninstalling google-ai-generativelanguage-0.6.15:\n",
      "      Successfully uninstalled google-ai-generativelanguage-0.6.15\n",
      "Successfully installed filetype-1.2.0 google-ai-generativelanguage-0.6.17 langchain-google-genai-2.1.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "google-generativeai 0.8.4 requires google-ai-generativelanguage==0.6.15, but you have google-ai-generativelanguage 0.6.17 which is incompatible.\n",
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain-google-genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: beautifulsoup4 in .\\venv\\lib\\site-packages (4.13.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in .\\venv\\lib\\site-packages (from beautifulsoup4) (2.6)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in .\\venv\\lib\\site-packages (from beautifulsoup4) (4.12.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install beautifulsoup4"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
